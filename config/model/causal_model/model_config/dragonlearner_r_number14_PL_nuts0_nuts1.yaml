batch_size: 32
br_size: 64
dropout: 0.02557259388666848
fc_hidden_size: 64
input_dropout: 0.0531818265155534
l1_lambda: 0.00019131321821625556
l2_lambda: 0.00020366983999367145
learning_rate: 0.003485439530630172
seq_hidden_size: 128
seq_num_layers: 1
window_size: 7
