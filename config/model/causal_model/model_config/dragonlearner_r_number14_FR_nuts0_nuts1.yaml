batch_size: 128
br_size: 32
dropout: 0.009173194062697032
fc_hidden_size: 128
input_dropout: 0.028844962561839875
l1_lambda: 0.00013956347310138228
l2_lambda: 0.00011658907413840419
learning_rate: 0.0013730753068435118
seq_hidden_size: 128
seq_num_layers: 2
window_size: 14
