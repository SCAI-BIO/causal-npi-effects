batch_size: 32
br_size: 128
dropout: 0.00276902287860974
fc_hidden_size: 16
input_dropout: 0.6324112580771333
l1_lambda: 1.0137023223769717e-05
l2_lambda: 1.0554237196091848e-05
learning_rate: 0.0008540536326903831
seq_hidden_size: 128
seq_num_layers: 2
window_size: 21
