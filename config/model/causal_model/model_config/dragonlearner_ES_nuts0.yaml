batch_size: 32
br_size: 64
dropout: 0.23533590656047113
fc_hidden_size: 128
input_dropout: 0.16612806840929445
l1_lambda: 3.6976948328710224e-05
l2_lambda: 0.001941450285534953
learning_rate: 0.0048691775204279955
seq_hidden_size: 128
seq_num_layers: 2
window_size: 7
