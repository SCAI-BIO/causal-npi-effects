batch_size: 32
br_size: 128
dropout: 0.1988587088082832
fc_hidden_size: 128
input_dropout: 0.0003290896310400304
l1_lambda: 1.304176102693014e-05
l2_lambda: 0.0003154678447843339
learning_rate: 0.0008729233515844118
seq_hidden_size: 128
seq_num_layers: 2
window_size: 14
