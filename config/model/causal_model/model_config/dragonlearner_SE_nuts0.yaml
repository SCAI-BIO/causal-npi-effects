batch_size: 32
br_size: 128
dropout: 0.04621437466328443
fc_hidden_size: 128
input_dropout: 0.8254811832070508
l1_lambda: 1.1238005564193008e-05
l2_lambda: 1.9613590405771256e-05
learning_rate: 0.006977506416037459
seq_hidden_size: 128
seq_num_layers: 1
window_size: 14
