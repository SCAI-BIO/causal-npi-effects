batch_size: 64
br_size: 128
dropout: 0.021669038790885983
fc_hidden_size: 128
input_dropout: 0.05567852667362527
l1_lambda: 4.169271330964523e-05
l2_lambda: 0.0005979252950905658
learning_rate: 0.0007519335052772796
seq_hidden_size: 128
seq_num_layers: 1
window_size: 7
