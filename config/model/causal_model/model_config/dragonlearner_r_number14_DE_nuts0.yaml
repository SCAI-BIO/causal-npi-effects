batch_size: 32
br_size: 64
dropout: 0.00417672310929235
fc_hidden_size: 128
input_dropout: 0.025919643087694365
l1_lambda: 3.847476704634042e-05
l2_lambda: 1.2862115396915056e-05
learning_rate: 0.005073181491381379
seq_hidden_size: 64
seq_num_layers: 1
window_size: 14
